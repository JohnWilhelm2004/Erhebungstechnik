---
title: "Bericht_Erhebungstechnik"
author: "John Wilhelm, Lukas König, Annika Homm"
date: "2026-01-20"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1. Einleitung

Die Digitalisierung hat das Studium an der Universität in den letzten Jahren fundamental verändert. Anstatt das Besuchen der Vorlesungen, bearbeiten von wöchentlichen Übungsblättern und das durchackern des offiziellen Skriptes steht Studierenden heute ein unüberschaubares Angebot an Lernressourcen zur Verfügung welche alle einen Weg zum Lernerfolg bieten. YouTube-Videos welche komplexe Themen in unter 10 Minuten erklären oder KI-Tools, welche Aufgaben in Sekundenschnelle gelöst werden. Die Digitalisierung bietet Freiheit und Effizienz wie noch nie zuvor. Doch dabei stellt sich die Frage ob diese Freiheit auch zu einem genauso tieferen Verständnis führt wie wenn man sich Intensiv mit den Themen beschäftigt.\
Der folgende Bericht verfolgt das Ziel zu untersuchen wie Studierende der Technischen Universität Dortmund die verfügbaren Lernressourcen nutzen und ob eher traditionelle Mittel ein tieferes Verständnis und Zufriedenheit bringen oder die Mittel der Digitalisierung. Dabei werden nicht nur die Nutzungshäufigkeiten der Lernmaterialien betrachtet, sondern auch, welche Eigenschaften, wie Verfügbarkeit, Verständlichkeit und Zufriedenheit diese bieten. Um mögliche Zusammenhänge differenzierter zu betrachten, werden individuelle Studienmerkmale, wie Fachsemester, Fakuktätzugehörigkeit und Abschluss des jeweiligen Studienganges erhoben.

## 1.1. Forschungsfragen

Im Zentrum fokussiert sich der Bericht auf die 2 folgenden Leitfragen.

1.  Unterstützt der Wunsch nach selbstbestimmten Lernen durch Künstliche Intelligenz und YouTube-Videos wirklich den Lernerfolg und führt dieses zu besseren akademischen Ergebnissen oder ist die traditionelle Führung durch universitäre Materialen wie Skripte und Übungen noch immer der sicherste Weg für das bestehen der Prüfungen.
2.  Gibt uns die Verfügbarkeit der Digitalen Hilfsmittel die Zufriedenheit wie wir sie brauchen? Um dies zu beantworten vergleichen wir Studierende mit einer hohen Nutzung an digitalen Hilfsmittel mit jenen, welche stärker auf klassische Medien setzen um herauszufinden, ob die Effizienz der Digitalisierung den Stress reduziert oder durch Überflutung sogar fördert.

## 1.2. Motivation und Zielsetzung

Durch eigene Erfahrung wissen wir das es manchmal einfach bequemer ist schnell und Effizient Aufgaben zu bearbeiten, jedoch kann dies auch schnell zu einer Überforderung führen. Zudem bleiben die Themen eher im Kurzzeitgedächtnis zu hängen wenn man sich nicht intensiv mit diesen beschäftigt. Was auf den ersten Blick hilfreich wirkt kann aber auch schnell das Gegenteil bewirken weshalb dieser Bericht diese Unsicherheit Studierenden nehmen soll. Ziel ist es evidenzbasierte Empfehlungen aussprechen zu können und zu zeigen, welche Strategien sich in der Praxis besser durchsetzen als andere.

# 2. Erhebungsinstrument

## 2.1 Wahl des Erhebungsinstruments

Um die Leitfragen zu beantworten, wurde ein Online-Fragebogen genutzt, welcher sich gut eignet, um subjektive Einschätzungen zu erfassen. Fragebögen stellen eine der gängigsten Methoden dar, um Erfahrungen der Befragten zu erheben, während zeitgleich die Erfassung von Nutzungshäufigkeiten der verschiedenen Lernressourcen in sauberen und einheitlichen ermöglicht wird. Zudem bekommen alle Befragten die selben Fragen und somit auch identischen Skalen, wodurch Antworten vergleichbar sind und Unterschiede sich deskriptiv auswerten lassen. Interviews wären eine mögliche Alternative, jedoch sind diese Zeit intensiver und erschweren das Vergleichen der Auswertungen.

## 2.2 Aufbau des Fragebogens

Der Fragebogen ist thematisch unterteilt worden, damit die Auswertung strukturierter stattfinden kann. Zu Beginn wird die Angkerfrage gestellt, welche direkt eine ehrliche Reflektion des Befragten über deren Studienzufriedenheit fordert. Um Unterschiede in den Fachrichtungen berücksichtigen zu können werden studienbezogene Angaben erhoben (u.a. Fakultät, Fachsemester und angestrebter Abschluss). Anschließend werden mehrere Itemblöcke in Form von Likert-Skalen verwendet, um die zentralen Fragen der zu erfassen. Diese beinhalten Fragen zur Einstellung gegenüber der Struktur und dem Übungsbetrieb der Kurse, wie die Meinung zu verpflichtenden Übungen. Zudem werden mit einer Matrixfrage die Nutzungshäufigkeiten der Materialen, welche sich aus Skripte, eigenen Mitschriften, Videos, Übungsaufgaben mit Musterlösungen, Altklausuren, Fachbüchern, Online-Videos und Chatbots zusammenstellen, erhoben. Danach wird die Qualitäts- und Wirkempfindung dieser Materialien erfasst, hinsichtlich Verständlichkeit, Struktur, rechtzeitiger Verfügbarkeit, Lernunterstützung und Lernaufwand. Im Anschluss werden wieder per Likert-Skalen prüfungsbezogene Aspekte wie die Sicherheit zum reichlichen Verständnis der Inhalte in hinsicht auf die nächste Prüfung. Abschließen gibt es die Möglichkeit in einem Textfeld eine Rückmeldung zur Umfrage zu geben.\
Die Fragen können meistens auf einer fünfstufigen Antwortskala beantwortet werden. Dabei konnte man von zwischen "stimme überhaupt nicht zu" bis zu "stimme voll und ganz zu" bei Zustimmungsaussagen und zwischen "gar nicht" bis "immer" bei Nutzungshäufigkeiten wählen. Die Variablen Fakultät und Abschluss sind nominal skaliert, dass Fachsemester wird als metrische Angabe erhoben und die Likert-Items sind ordninal skaliert.

## 2.3. Durchführung

Die Umfrage wurde als Online-Umfrage mit der Software LimeSurvey erstellt und durchgeführt. Über einen QR-Code konnten Studierende auf diese Zugriff erhalten und den Fragebogen ohne Anmeldung oder Beziehung sonstiger Persönlicher bezogener Daten ausfüllen. Teilnehmer wurden per Link in Whatsapp-Gruppen oder in direktem Kontakt am Campusgelände der Technischen Universität Dortmund erreicht. Die Teilnahme erfolgte auf freiwilliger Basis und richtete sich an Studierende unterschiedlicher Fachsemester und Fachrichtungen, jedoch mit dem Fokus auf die MINT Fächer (Mathe, Informatik, Naturwissenschaften, Technik).

## 2.4. Bias/ Einschränkung der Rekrutierung

Durch das direkte Ansprechen sind methodische Einschränkungen unvermeidbar. Nur Studierende welche zu dieser Zeit vor Ort waren konnten erreicht werden, weshalb Studierende welche sich nur selten am Campus aufhalten oder eher online Studieren seltener Vertreten sein werden. So entsteht ein SSelection Bias, da diese Representantengruppe unterrepräsentiert wird. Zudem konnten auch nur Studierende an der Befragung teilnehmen, welche auch Interesse und ausreichend Zeit hatten. Es zeigt sich außerdem eine ungleichmäßige Verteilung der Fakultäten und Fachsemester, vor allem bei den Studierenden der Statistik, welche dadurch überrepräsentiert sein könnten. Diese Verzerrungen verhindern das Generalisieren der Ergebnisse was zu folge hat, dass diese primär nur für die erreichte Stichprobe zu interpretieren sind.

## 2.5. Stichprobe und Datensatz

### 2.5.1 Erhebung

Die vorliegenden Resultate basieren auf einer standardisierten Online-Erhebung, welche mit LimeSurvey durchgeführt wurde. Über einen QR-Code konnten Studierende diese Aufrufen und direkt teilnehmen. Die Teilnehmer wurden darüber informiert, dass die Umfrage Anonym und Freiwillig ist und keine personenbezogenen Daten erfragt werden. Die Umfrage wurde im Vorfeld von einer Gruppe Studierender erstellt und überprüft. Die Erstellung und Auswertung wurde im Rahmen der Veranstaltung Erhebungstechnik durchgeführt und fokussiert sich auf den Vergleich der traditionellen und Digitalen Lernmethoden und deren Qualität für Studierende.

### 2.5.2. Stichprobe

Es nahmen 128 Studierende an der Umfrage teil, wovon nach Aufbereitung die Ergebnisse von 83 Studierenden entwertet und interpretiert werden konnten. Die Umfrage erfolgte im Umfeld Fakultät Statistik, sodass eine Gelegenheitsstichprobe vorliegt. Dadurch sind Selektions- und Selbstselektionsverzerrungen möglich. Deshalb ist wichtig zu beachten, dass die vorliegenden Ergebnisse nicht zur Beantwortung der Leitfragen direkt dient und nur einen Teil der Grundgesamtheit darstellt. Die Auswertung fokussiert sich also nur auf die Stichprobe und soll eine Empfehlung aussprechen.

### 2.5.3. Datensatz und Arbeitsgrundlage

Zur Auswertung wurde eine von LimeSurvey erstellte CSV. Datei verwendet. Diese wurde vorerst bereinigt und zur Analyse angepasst, indem Variablen zusammengeführt, umbenannt und in die nötigen numerischen Skalen umgewandelt wurden. Insgesamt umfasst der Datensatz 31 Variablen welche die Fragebogenblöcke zu Studienmerkmalen, Lernerfolg, Einstellungen, Nutzung, Qualitätsurteilen sowie Wirkung/Effekten bilden. Zu Darstellungszwecken und einer übersichtlicheren Auswertung wurden verschiedene Bezeichnungen verkürzt (z.B. Nutzung, Qualität,...).

### 2.5.4. Variablen und Skalenniveaus

Der Datensatz enthält kategoriale Studienmerkmale sowie überwiegend ordinal skalierte Likert-Items, welche numerisch kodiert vorliegen:

-   Nominal ( 2 Variablen): Fakultät, Abschluss

-   Metrisch (1 Variable): Fachsemester

-   Ordinal (Likert: 28 Variablen) u. a. ZufriedenheitScore (subjektive Zufriedenheit mit Lernerfolg), Einstellungsitems zur Kursstruktur und zum Übungsbetrieb, Nutzungshäufigkeiten verschiedener Lernmaterialen (Skripte, Mitschriften, Videoaufzeichnungen, Übungsaufgaben, Bücher, Altklausuren, Online-Videos, KI-Chatbots) sowie Urteile zur Qualität der Materialien und wahrgenommene Effekte (Motivation, Sicherheit, Arbeitsbelastung, Prüfungsstress, Zeitaufwand, Prüfungsrelevanz). Das Freitextfeld welches ein Feedback ermöglicht wurde erhoben, ist jedoch kein Bestandteil der bereinigten CSV Datei, da diese keinen Entscheidenen Faktor spielen.

### 2.5.5. Datenaufbereitung und fehlende Werte

Damit die Analyse qualitativ vollzogen werden konnte wurden folgende Änderungen an der Roh Datei vollzogen:

1.  Bereinigung von Merkmalen und Skalen: Kategoriale Merkmale wurden in nominale Variablen und Skalenwerte als numerische Variablen gespeichert.
2.  Umskalierung: Likert-Items wurden in numerische Werte zwischen 1-5 codiert (1 = niedrigstes Vorkommen, 5 = häufigstes Vorkommen), wodurch die Vergleichbarkeit vereinfacht wurde.
3.  Fehlende Werte: Unbeantwortete Items wurden als NA kodiert. Insgesamt liegen 107 NAs über alle Variablen verteilt vor. 53 Personen haben die Umfrage vollständig beantwortet. Im Durchschnitt hat jeder Teilnehmer 1,26 fehlende Werte.

Die 107 fehlenden Werte setzen sich wie folgt zusammen:

-   Studienmerkmale (3 Variablen): 5 NA
-   Lernerfolg (2 Variablen): 2 NA
-   Einstellungen (5 Variablen): 12 NA
-   Nutzung Lernmaterialien (9 Variablen): 46 NA
-   Qualität (5 Variablen): 10 NA
-   Effekte (7 Variablen): 32 NA
